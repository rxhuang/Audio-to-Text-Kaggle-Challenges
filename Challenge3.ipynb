{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of hw3p2",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZAUaNrQ_KHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b6d8b68-bd9c-4777-ca10-a863476c118d"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"ruoxinhuang\" \n",
        "os.environ['KAGGLE_KEY'] = \"f9d6d5aade71452503766f80812da73d\"\n",
        "!kaggle competitions download -c 11-785-fall-20-homework-3\n",
        "!unzip dev.npy.zip\n",
        "!unzip dev_labels.npy.zip\n",
        "!unzip phoneme_list.py\n",
        "!unzip test.npy.zip\n",
        "!unzip train.npy.zip\n",
        "!unzip train_labels.npy.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.9 / client 1.5.4)\n",
            "Downloading dev_labels.npy.zip to /content\n",
            "  0% 0.00/236k [00:00<?, ?B/s]\n",
            "100% 236k/236k [00:00<00:00, 51.1MB/s]\n",
            "Downloading dev.npy.zip to /content\n",
            " 85% 84.0M/98.6M [00:00<00:00, 61.9MB/s]\n",
            "100% 98.6M/98.6M [00:01<00:00, 95.0MB/s]\n",
            "Downloading train_labels.npy.zip to /content\n",
            "  0% 0.00/3.21M [00:00<?, ?B/s]\n",
            "100% 3.21M/3.21M [00:00<00:00, 94.5MB/s]\n",
            "Downloading train.npy.zip to /content\n",
            " 99% 1.56G/1.57G [00:25<00:00, 69.1MB/s]\n",
            "100% 1.57G/1.57G [00:25<00:00, 66.6MB/s]\n",
            "Downloading test.npy.zip to /content\n",
            " 74% 73.0M/98.1M [00:02<00:01, 24.7MB/s]\n",
            "100% 98.1M/98.1M [00:02<00:00, 45.5MB/s]\n",
            "Downloading phoneme_list.py to /content\n",
            "  0% 0.00/1.06k [00:00<?, ?B/s]\n",
            "100% 1.06k/1.06k [00:00<00:00, 660kB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/16.5k [00:00<?, ?B/s]\n",
            "100% 16.5k/16.5k [00:00<00:00, 9.49MB/s]\n",
            "sample_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  dev.npy.zip\n",
            "  inflating: dev.npy                 \n",
            "Archive:  dev_labels.npy.zip\n",
            "  inflating: dev_labels.npy          \n",
            "Archive:  phoneme_list.py\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of phoneme_list.py or\n",
            "        phoneme_list.py.zip, and cannot find phoneme_list.py.ZIP, period.\n",
            "Archive:  test.npy.zip\n",
            "  inflating: test.npy                \n",
            "Archive:  train.npy.zip\n",
            "  inflating: train.npy               \n",
            "Archive:  train_labels.npy.zip\n",
            "  inflating: train_labels.npy        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk766cI53LHx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8ac30b3-6451-421d-c14a-f1ca4afa4b0d"
      },
      "source": [
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!pip install wget\n",
        "%cd ctcdecode\n",
        "!pip install .\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ctcdecode'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 1063 (delta 6), reused 7 (delta 2), pack-reused 1047\u001b[K\n",
            "Receiving objects: 100% (1063/1063), 763.61 KiB | 1.75 MiB/s, done.\n",
            "Resolving deltas: 100% (509/509), done.\n",
            "Submodule 'third_party/ThreadPool' (https://github.com/progschj/ThreadPool.git) registered for path 'third_party/ThreadPool'\n",
            "Submodule 'third_party/kenlm' (https://github.com/kpu/kenlm.git) registered for path 'third_party/kenlm'\n",
            "Cloning into '/content/ctcdecode/third_party/ThreadPool'...\n",
            "remote: Enumerating objects: 82, done.        \n",
            "remote: Total 82 (delta 0), reused 0 (delta 0), pack-reused 82\n",
            "Cloning into '/content/ctcdecode/third_party/kenlm'...\n",
            "remote: Enumerating objects: 90, done.        \n",
            "remote: Counting objects: 100% (90/90), done.        \n",
            "remote: Compressing objects: 100% (64/64), done.        \n",
            "remote: Total 13672 (delta 41), reused 54 (delta 21), pack-reused 13582        \n",
            "Receiving objects: 100% (13672/13672), 5.53 MiB | 7.39 MiB/s, done.\n",
            "Resolving deltas: 100% (7847/7847), done.\n",
            "Submodule path 'third_party/ThreadPool': checked out '9a42ec1329f259a5f4881a291db1dcb8f2ad9040'\n",
            "Submodule path 'third_party/kenlm': checked out '35835f1ac4884126458ac89f9bf6dd9ccad561e0'\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=1d1a065a5ccf8afe9cf78ae907da40e9300ea770ee1f562bf52c441dc9949961\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "/content/ctcdecode\n",
            "Processing /content/ctcdecode\n",
            "Building wheels for collected packages: ctcdecode\n",
            "  Building wheel for ctcdecode (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ctcdecode: filename=ctcdecode-1.0.2-cp36-cp36m-linux_x86_64.whl size=12756161 sha256=349085b7bb18a5f937a44c57fdf1cd5ac843ed5c1fa5edc5ddd69631caa241f4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3i3mfdbg/wheels/c3/6c/94/7d57d4f20a87a22ef1722eaad22052b4c435892b55400e5f4e\n",
            "Successfully built ctcdecode\n",
            "Installing collected packages: ctcdecode\n",
            "Successfully installed ctcdecode-1.0.2\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg5DUCT3XkOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff88f684-134f-418a-a8e9-24ce930b5584"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPbWx2xiHUN3"
      },
      "source": [
        "train = np.load('train.npy', allow_pickle=True, encoding=\"latin1\")\n",
        "train_labels = np.load('train_labels.npy', allow_pickle=True, encoding=\"latin1\")\n",
        "\n",
        "dev = np.load('dev.npy', allow_pickle=True, encoding=\"latin1\")\n",
        "dev_labels = np.load('dev_labels.npy', allow_pickle=True, encoding=\"latin1\")\n",
        "\n",
        "test = np.load('test.npy', allow_pickle=True, encoding=\"latin1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHXQl5MFADnp"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "  def __init__(self, X, Y):\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    X = self.X[index]\n",
        "    Y = self.Y[index] + 1\n",
        "    return torch.from_numpy(X).float(), X.shape[0], torch.from_numpy(Y).long(), Y.shape[0]                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpRx9JO89Jz8"
      },
      "source": [
        "def collate(batch):\n",
        "  X = [i[0] for i in batch]\n",
        "  X_len = [i[1] for i in batch]\n",
        "  Y = [i[2] for i in batch]\n",
        "  Y_len = [i[3] for i in batch]\n",
        "\n",
        "  X_pad = nn.utils.rnn.pad_sequence(X, batch_first=False, padding_value=0.0)\n",
        "  Y_pad = nn.utils.rnn.pad_sequence(Y, batch_first=True, padding_value=0)\n",
        "\n",
        "\n",
        "  return X_pad,X_len,Y_pad,Y_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsbojNaqAbkz"
      },
      "source": [
        "train_dataset = MyDataset(train, train_labels)\n",
        "train_loader_args = dict(shuffle=True, batch_size=64, num_workers=4, pin_memory=True, collate_fn = collate)\n",
        "train_loader = DataLoader(train_dataset, **train_loader_args)\n",
        "\n",
        "\n",
        "dev_dataset = MyDataset(dev, dev_labels)\n",
        "dev_loader_args = dict(shuffle=True, batch_size=64, num_workers=4, pin_memory=True, collate_fn = collate)\n",
        "dev_loader = DataLoader(dev_dataset, **dev_loader_args)\n",
        "\n",
        "test_dataset = MyDataset(test, train_labels[:len(test)])\n",
        "test_loader_args = dict(shuffle=False, batch_size=64, num_workers=4, pin_memory=True, collate_fn = collate)\n",
        "test_loader = DataLoader(test_dataset, **test_loader_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGaOWwf47zdw"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input, output, hidden_size):\n",
        "        super(Model, self).__init__()\n",
        "        self.lstm = nn.LSTM(input, hidden_size, num_layers = 3, bidirectional=True, dropout=0.5)\n",
        "        self.linear = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.output = nn.Linear(hidden_size, output)\n",
        "    \n",
        "    def forward(self, X, lengths):\n",
        "        packed_X = nn.utils.rnn.pack_padded_sequence(X, lengths, enforce_sorted=False)\n",
        "        packed_out = self.lstm(packed_X)[0]\n",
        "        out, out_lens = nn.utils.rnn.pad_packed_sequence(packed_out)\n",
        "        # Log softmax after output layer is required since`nn.CTCLoss` expects log probabilities.\n",
        "        out = self.linear(out)\n",
        "        out = self.output(out).log_softmax(2)\n",
        "        return out, out_lens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRyZ5PHiWb54"
      },
      "source": [
        "def train_one_epoch(model, train_loader, optimizer):\n",
        "    \n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  count = 0\n",
        "\n",
        "  for X, X_lens, Y, Y_lens in train_loader:\n",
        "      X = X.to(device)\n",
        "      Y = Y.to(device)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      out, out_lens = model(X, X_lens)\n",
        "      loss = criterion(out, Y, out_lens.tolist(), Y_lens)\n",
        "      count +=1\n",
        "      total_loss += loss.item()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "  print(total_loss/count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fErDSusE9aHe"
      },
      "source": [
        "model = Model(13, 42, 256)\n",
        "model.to(device)\n",
        "criterion = nn.CTCLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), weight_decay=5e-6, lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.85)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR3A5rmWWBAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a9aceda-0ffb-421d-d8b8-155fb8065147"
      },
      "source": [
        "for i in range(20):\n",
        "  train_one_epoch(model, train_loader, optimizer)\n",
        "  #scheduler.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.700822887032531\n",
            "3.200249103612678\n",
            "1.771767225722934\n",
            "1.0384225077753844\n",
            "0.8470092453928881\n",
            "0.7430530613244966\n",
            "0.6806930636250695\n",
            "0.6343992612389631\n",
            "0.598560280578081\n",
            "0.5741458729256032\n",
            "0.5526888256156167\n",
            "0.5224685649885688\n",
            "0.5122270928046038\n",
            "0.5033984678949035\n",
            "0.5020077262333659\n",
            "0.47501810241577236\n",
            "0.46618958519295206\n",
            "0.4540723036368226\n",
            "0.44034592530062033\n",
            "0.42916270640007287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msuCFFs9M9m-"
      },
      "source": [
        "from ctcdecode import CTCBeamDecoder\n",
        "from phoneme_list import PHONEME_MAP\n",
        "\n",
        "decoder = CTCBeamDecoder(PHONEME_MAP, beam_width=10, log_probs_input=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGIZ9DJcwPXG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c3451de-2e65-4066-e2fb-2f288db68cad"
      },
      "source": [
        "from nltk.metrics.distance import edit_distance\n",
        "model.eval()\n",
        "torch.no_grad()\n",
        "distance = 0\n",
        "total_loss = 0\n",
        "count = 0\n",
        "\n",
        "for X, X_lens, Y, Y_lens in dev_loader:\n",
        "  X = X.to(device)\n",
        "  out, out_lens = model(X, X_lens)\n",
        "  loss = criterion(out, Y, out_lens.tolist(), Y_lens)\n",
        "  count +=1\n",
        "  total_loss += loss.item()\n",
        "  beam, _, _, out_lens = decoder.decode(torch.transpose(out,0,1),out_lens)\n",
        "  beam = beam[:,0]\n",
        "  out_lens = out_lens[:,0]\n",
        "\n",
        "\n",
        "  for i, lengths in enumerate(out_lens):\n",
        "    output = beam[i][:lengths]\n",
        "    label = ''.join([PHONEME_MAP[idx] for idx in Y[i][:Y_lens[i]]])\n",
        "    output = ''.join([PHONEME_MAP[idx] for idx in output])\n",
        "    distance += edit_distance(output,label)\n",
        "print(total_loss/count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5290674647769412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENZeLtV03Sq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb2fc4cc-0e77-477e-fdb0-0a0f0756895e"
      },
      "source": [
        "distance/len(dev_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.634648370497427"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8HpoobC1Ath"
      },
      "source": [
        "result = []\n",
        "model.eval()\n",
        "torch.no_grad()\n",
        "\n",
        "for X, X_lens, Y, Y_lens in test_loader:\n",
        "  X = X.to(device)\n",
        "  out, out_lens = model(X, X_lens)\n",
        "  beam, _, _, out_lens = decoder.decode(torch.transpose(out,0,1),out_lens)\n",
        "  beam = beam[:,0]\n",
        "  out_lens = out_lens[:,0]\n",
        "\n",
        "  for i, lengths in enumerate(out_lens):\n",
        "    output = beam[i][:lengths]\n",
        "    output = ''.join([PHONEME_MAP[idx] for idx in output])\n",
        "    result.append(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q3bKmgHNZrl"
      },
      "source": [
        "import csv\n",
        "\n",
        "with open('submission4.csv', 'w') as csvfile:\n",
        "  csvwriter = csv.writer(csvfile)\n",
        "  csvwriter.writerow(('id','label'))\n",
        "  for i, row in enumerate(result):\n",
        "    csvwriter.writerow((i,row))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBJInDdLSSav"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}