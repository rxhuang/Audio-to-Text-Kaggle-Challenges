{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw1p2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI-e_N4VbsVP"
      },
      "source": [
        "!mkdir .kaggle\n",
        "\n",
        "import os, zipfile, tarfile\n",
        "os.environ['KAGGLE_USERNAME'] = \"ruoxinhuang\" \n",
        "os.environ['KAGGLE_KEY'] = \"f9d6d5aade71452503766f80812da73d\"\n",
        "!kaggle competitions download -c 11-785-fall-20-homework-1-part-2\n",
        "\n",
        "! unzip test.npy.zip -d kaggle\n",
        "! unzip dev.npy.zip -d kaggle\n",
        "! unzip dev_labels.npy.zip -d kaggle\n",
        "! unzip train.npy.zip -d kaggle\n",
        "! unzip train_labels.npy.zip -d kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TunRcO2jbvOj"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "train_x = np.load('kaggle/train.npy',allow_pickle=True)\n",
        "train_y = np.load('kaggle/train_labels.npy',allow_pickle=True)\n",
        "test_x = np.load('kaggle/dev.npy',allow_pickle=True)\n",
        "test_y = np.load('kaggle/dev_labels.npy',allow_pickle=True)\n",
        "final_x = np.load('kaggle/test.npy',allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF7pesefb1OY"
      },
      "source": [
        "context = 20\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmAq2sdygAHy"
      },
      "source": [
        "class SpeechDataset(Dataset):\n",
        "    def __init__(self, X, Y=None, context=20):\n",
        "        self.curr_utt = 0\n",
        "        self.utt_lengths = np.zeros(len(X)) #stores number of data points until utt\n",
        "        self.d = {} #which utt datapoint belongs to\n",
        "        self.context = context\n",
        "        \n",
        "        for idx,utt in enumerate(X):\n",
        "            if idx == 0:\n",
        "                self.utt_lengths[idx] = len(utt)\n",
        "            else:\n",
        "                self.utt_lengths[idx] = self.utt_lengths[idx-1]+len(utt)\n",
        "                \n",
        "            for i in range(len(utt)):\n",
        "                if idx == 0:\n",
        "                    self.d[i] = idx\n",
        "                else:\n",
        "                    self.d[i+self.utt_lengths[idx-1]] = idx\n",
        "        \n",
        "        pad = np.zeros((self.context,13))\n",
        "\n",
        "        self.X = [torch.tensor(np.concatenate((pad,utt,pad),axis=0)) for utt in X]\n",
        "        if Y is None:\n",
        "          self.Y = None\n",
        "        else:\n",
        "          self.Y = [torch.tensor(utt) for utt in Y]\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return int(self.utt_lengths[-1])\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        utt_num = int(self.d[idx])\n",
        "        if utt_num!=0:\n",
        "          idx = int(idx - self.utt_lengths[utt_num-1])\n",
        "        \n",
        "        \n",
        "        X = self.X[utt_num][idx:idx+2*self.context+1].flatten()\n",
        "        if self.Y is None:\n",
        "          Y = None\n",
        "        else:\n",
        "          Y = self.Y[utt_num][idx]\n",
        "\n",
        "        return (X,Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqd3Rm0Ikgut"
      },
      "source": [
        "def get_dataloader(trainset, valset = None, batch_size = 384, num_workers = 4):\n",
        "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers,drop_last = True)\n",
        "    \n",
        "    if(valset is None):\n",
        "        val_loader = None\n",
        "    else:\n",
        "        val_loader = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=num_workers,drop_last = True)\n",
        "        \n",
        "    return (train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz1oT8uvkTy5"
      },
      "source": [
        "trainset = SpeechDataset(train_x,train_y)\n",
        "train_loader, _ = get_dataloader(trainset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1Xw9CcNmU8K"
      },
      "source": [
        "def train_one_epoch(model, train_loader, optimizer):\n",
        "    \n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "    acc = 0\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        y_hat = model(x.float())\n",
        "        loss = criterion(y_hat, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        #compute loss and accuracy \n",
        "        count += 1\n",
        "        total_loss += loss.item()\n",
        "        values, indices = y_hat.max(1)\n",
        "        acc += (y-indices == 0).sum(dim=0).item()\n",
        "    \n",
        "    return(total_loss/count, acc/len(train_loader.dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3G7aan7mXR4"
      },
      "source": [
        "model = nn.Sequential(\n",
        "            nn.Linear((context*2+1)*13, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Linear(1024, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(2048),\n",
        "            nn.Linear(2048, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(4096),\n",
        "            nn.Linear(4096, 5120),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(5120),\n",
        "            nn.Linear(5120, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(4096),\n",
        "            nn.Linear(4096, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(2048),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Linear(1024, 346)\n",
        "        )\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCELOSS()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBtvCwN50cFC"
      },
      "source": [
        "#train for 3 epoches\n",
        "for i in range(3):\n",
        "  avg_train_loss, train_accuracy = train_one_epoch(model, train_loader, optimizer)\n",
        "  print(train_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6LINq4E7gbz"
      },
      "source": [
        "def validate_model(model, val_loader):  \n",
        "    \"\"\"\n",
        "    Validate a given model with a validation dataloader.\n",
        "    \n",
        "    args:\n",
        "        model (nn.Module): the trained model \n",
        "        val_loader (DataLoader): iterable for valset minibatches\n",
        "\n",
        "    return: Tuple(avg_val_loss, val_accuracy, val_time)\n",
        "        avg_val_loss (float): average validation loss across batches\n",
        "        val_accuracy (float): portion of correctly classified images in the validation dataset\n",
        "        val_time (float): the time taken to run this function\n",
        "    \"\"\"\n",
        "    \n",
        "    model.eval()\n",
        "    torch.no_grad()\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "    acc = 0\n",
        "    \n",
        "    for x, y in val_loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        y_hat = model(x.float())\n",
        "        loss = criterion(y_hat, y)\n",
        "        \n",
        "        #compute loss and accuracy \n",
        "        count += 1\n",
        "        total_loss += loss.item()\n",
        "        values, indices = y_hat.max(1)\n",
        "        acc += (y-indices == 0).sum(dim=0).item()\n",
        "\n",
        "    \n",
        "    \n",
        "    return(total_loss/count, acc/len(val_loader.dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi8KW27--JW-"
      },
      "source": [
        "valset = SpeechDataset(test_x,test_y)\n",
        "train_loader, val_loader = get_dataloader(trainset,valset)\n",
        "avg_val_loss, val_accuracy = validate_model(model, val_loader)\n",
        "print(val_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlApI8iDvaxh"
      },
      "source": [
        "finalset = SpeechDataset(final_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaFdceTTCduk"
      },
      "source": [
        "model.eval()\n",
        "result = []\n",
        "\n",
        "for x, y in finalset:\n",
        "    x = x.to(device)\n",
        "    y_hat = model(x.unsqueeze_(0).float())\n",
        "    values, indices = y_hat.max(1)\n",
        "    result.append(indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4ClvdqeKV8K"
      },
      "source": [
        "result = [np.array(x.cpu()) for x in result]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw0CRJCrKcr1"
      },
      "source": [
        "import csv\n",
        "\n",
        "with open('sample.csv', 'w') as csvfile:\n",
        "  csvwriter = csv.writer(csvfile)\n",
        "  csvwriter.writerow(('id','label'))\n",
        "  for i, row in enumerate(result):\n",
        "    csvwriter.writerow((i,row.item()))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}