{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw2p2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT_5lA6uGcuf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b17eba9a-ecc6-4de9-c610-5af392f9d4c4"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"ruoxinhuang\" \n",
        "os.environ['KAGGLE_KEY'] = \"f9d6d5aade71452503766f80812da73d\"\n",
        "!kaggle datasets download -d cmu11785/20fall-hw3p2\n",
        "!unzip 20fall-hw3p2.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "404 - Not Found\n",
            "unzip:  cannot find or open 20fall-hw3p2.zip, 20fall-hw3p2.zip.zip or 20fall-hw3p2.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eH5FSU1j1An"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.metrics import pairwise\n",
        "\n",
        "import torch\n",
        "import torchvision   \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJR5Lr8ckqzj"
      },
      "source": [
        "imageFolder_dataset = torchvision.datasets.ImageFolder(root='classification_data/train_data', \n",
        "                                                       transform=torchvision.transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_8WIndupt9t"
      },
      "source": [
        "imageFolder_dataloader = DataLoader(imageFolder_dataset, batch_size=10, shuffle=True, num_workers=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7lVrT3IpvwS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c631276b-29c0-454d-c3de-1239118b1058"
      },
      "source": [
        "imageFolder_dataset.__len__(), len(imageFolder_dataset.classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(380638, 4000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guz_xtmbpxAM"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, num_feats, hidden_sizes, num_classes, feat_dim=4000):\n",
        "        super(Network, self).__init__()\n",
        "        \n",
        "        self.hidden_sizes = [num_feats] + hidden_sizes + [num_classes]\n",
        "        \n",
        "        self.layers = []\n",
        "        for idx, channel_size in enumerate(hidden_sizes):\n",
        "            self.layers.append(nn.Conv2d(in_channels=self.hidden_sizes[idx], \n",
        "                                         out_channels=self.hidden_sizes[idx+1], \n",
        "                                         kernel_size=3, stride=1, padding=1, bias=False))\n",
        "            self.layers.append(nn.BatchNorm2d(self.hidden_sizes[idx+1]))\n",
        "            self.layers.append(nn.ReLU(inplace=True))\n",
        "            if(idx==3 or idx==5):\n",
        "              self.layers.append(nn.Dropout(p=0.3))\n",
        "            if(idx==1 or idx==2 or idx==4 or idx==6 or idx==7 or idx==8):\n",
        "              self.layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "            \n",
        "        self.layers = nn.Sequential(*self.layers)\n",
        "        \n",
        "        # For creating the embedding to be passed into the Center Loss criterion\n",
        "        self.linear_closs = nn.Linear(self.hidden_sizes[-2], feat_dim, bias=False)\n",
        "\n",
        "    \n",
        "    def forward(self, x, evalMode=False):\n",
        "        output = x\n",
        "        output = self.layers(output)\n",
        "        output = F.avg_pool2d(output, [output.size(2), output.size(3)], stride=1)\n",
        "        output = output.reshape(output.shape[0], output.shape[1])\n",
        "        \n",
        "        # Create the feature embedding for the Center Loss\n",
        "        closs_output = self.linear_closs(output)\n",
        "        #closs_output = self.relu_closs(closs_output)\n",
        "\n",
        "        return closs_output\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_normal_(m.weight.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VocvI3XHrEBL"
      },
      "source": [
        "def train(model, data_loader, test_loader, task='Classification'):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(numEpochs):\n",
        "        avg_loss = 0.0\n",
        "        print('epoch',epoch)\n",
        "        for batch_num, (feats, labels) in enumerate(data_loader):\n",
        "            feats, labels = feats.to(device), labels.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(feats)\n",
        "\n",
        "            loss = criterion(outputs, labels.long())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            avg_loss += loss.item()\n",
        "\n",
        "   \n",
        "            \n",
        "            torch.cuda.empty_cache()\n",
        "            del feats\n",
        "            del labels\n",
        "            del loss\n",
        "        \n",
        "        if task == 'Classification':\n",
        "            val_loss, val_acc = test_classify(model, test_loader)\n",
        "            train_loss, train_acc = test_classify(model, data_loader)\n",
        "            print('Train Loss: {:.4f}\\tTrain Accuracy: {:.4f}\\tVal Loss: {:.4f}\\tVal Accuracy: {:.4f}'.\n",
        "                  format(train_loss, train_acc, val_loss, val_acc))\n",
        "        else:\n",
        "            test_verify(model, test_loader)\n",
        "        scheduler.step()\n",
        "\n",
        "def test_classify(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = []\n",
        "    accuracy = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_num, (feats, labels) in enumerate(test_loader):\n",
        "        feats, labels = feats.to(device), labels.to(device)\n",
        "        outputs = model(feats)\n",
        "        \n",
        "        _, pred_labels = torch.max(F.softmax(outputs, dim=1), 1)\n",
        "        pred_labels = pred_labels.view(-1)\n",
        "        \n",
        "        loss = criterion(outputs, labels.long())\n",
        "        \n",
        "        accuracy += torch.sum(torch.eq(pred_labels, labels)).item()\n",
        "        total += len(labels)\n",
        "        test_loss.extend([loss.item()]*feats.size()[0])\n",
        "        del feats\n",
        "        del labels\n",
        "\n",
        "    model.train()\n",
        "    return np.mean(test_loss), accuracy/total\n",
        "\n",
        "\n",
        "def test_verify(model, test_loader):\n",
        "    raise NotImplementedError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDOZcnTfrJCA"
      },
      "source": [
        "train_dataset = torchvision.datasets.ImageFolder(root='classification_data/train_data', \n",
        "                                                 transform=torchvision.transforms.ToTensor())\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=200, \n",
        "                                               shuffle=True, num_workers=8)\n",
        "\n",
        "dev_dataset = torchvision.datasets.ImageFolder(root='classification_data/val_data', \n",
        "                                               transform=torchvision.transforms.ToTensor())\n",
        "dev_dataloader = DataLoader(dev_dataset, batch_size=200, \n",
        "                                             shuffle=True, num_workers=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttyyntpHru4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2546b67-e131-4b3d-a13f-23db70f54662"
      },
      "source": [
        "numEpochs = 5\n",
        "num_feats = 3\n",
        "\n",
        "learningRate = 15e-2\n",
        "weightDecay = 5e-5\n",
        "\n",
        "hidden_sizes = [64, 64, 64, 128, 128, 256, 256, 256, 256]\n",
        "num_classes = len(train_dataset.classes)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwKrUzkwryoJ"
      },
      "source": [
        "network = Network(num_feats, hidden_sizes, num_classes)\n",
        "network.apply(init_weights)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=learningRate, weight_decay=weightDecay, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF_mct3OpWTb"
      },
      "source": [
        "decayRate = 0.85\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvYTD-Nbr2aU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "294c21fd-1f71-433f-a288-45794b29e01e"
      },
      "source": [
        "network.train()\n",
        "network.to(device)\n",
        "train(network, train_dataloader, dev_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0\n",
            "Train Loss: 8.0033\tTrain Accuracy: 0.0010\tVal Loss: 8.1386\tVal Accuracy: 0.0003\n",
            "epoch 1\n",
            "Train Loss: 7.8296\tTrain Accuracy: 0.0015\tVal Loss: 7.9520\tVal Accuracy: 0.0014\n",
            "epoch 2\n",
            "Train Loss: 7.3568\tTrain Accuracy: 0.0032\tVal Loss: 7.5112\tVal Accuracy: 0.0015\n",
            "epoch 3\n",
            "Train Loss: 7.4162\tTrain Accuracy: 0.0032\tVal Loss: 7.5616\tVal Accuracy: 0.0025\n",
            "epoch 4\n",
            "Train Loss: 7.6524\tTrain Accuracy: 0.0033\tVal Loss: 7.8380\tVal Accuracy: 0.0021\n",
            "epoch 5\n",
            "Train Loss: 7.3809\tTrain Accuracy: 0.0078\tVal Loss: 7.5767\tVal Accuracy: 0.0046\n",
            "epoch 6\n",
            "Train Loss: 7.4217\tTrain Accuracy: 0.0066\tVal Loss: 7.6073\tVal Accuracy: 0.0053\n",
            "epoch 7\n",
            "Train Loss: 7.1421\tTrain Accuracy: 0.0095\tVal Loss: 7.3469\tVal Accuracy: 0.0071\n",
            "epoch 8\n",
            "Train Loss: 7.2777\tTrain Accuracy: 0.0098\tVal Loss: 7.4943\tVal Accuracy: 0.0076\n",
            "epoch 9\n",
            "Train Loss: 7.5456\tTrain Accuracy: 0.0082\tVal Loss: 7.7623\tVal Accuracy: 0.0050\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BwkzfWx4bZU"
      },
      "source": [
        "f = open(\"verification_pairs_test.txt\", \"r\")\n",
        "lines = f.read().split('\\n')\n",
        "lines = np.array(lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYyKD7vI4-fF"
      },
      "source": [
        "lines = np.char.split(lines, sep =' ') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vZqx7H26Gko",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "b622fb18-f176-402d-fb33-86477259eead"
      },
      "source": [
        "for line in lines:\n",
        "  img = Image.open(line[0])\n",
        "  img = torchvision.transforms.ToTensor()(img)\n",
        "  img = img.reshape((1,3,64,64))\n",
        "  network.eval()\n",
        "  feats = img.to(device)\n",
        "  output1 = network(feats)\n",
        "\n",
        "  img = Image.open(line[1])\n",
        "  img = torchvision.transforms.ToTensor()(img)\n",
        "  img = img.reshape((1,3,64,64))\n",
        "  network.eval()\n",
        "  feats = img.to(device)\n",
        "  output2 = network(feats)\n",
        "\n",
        "  score = pairwise.cosine_similarity(output1.cpu().detach().numpy(),output2.cpu().detach().numpy())\n",
        "  line.append(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2812\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2813\u001b[0;31m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2814\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.str_' object has no attribute 'seek'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-527e08e8bdec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2813\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2815\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2816\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.str_' object has no attribute 'read'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYmt3czZ8CwX"
      },
      "source": [
        "import csv\n",
        "\n",
        "with open('submission3.csv', 'w') as csvfile:\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "    csvwriter.writerow(('Id','Category'))\n",
        "    for i in range(lines.shape[0]-1):\n",
        "        csvwriter.writerow((lines[i][0]+' '+lines[i][1],lines[i][2][0][0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFjxr6zoeDwe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}